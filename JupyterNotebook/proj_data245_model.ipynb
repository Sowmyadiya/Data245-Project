{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state</th>\n",
       "      <th>job_opportunity_rank</th>\n",
       "      <th>affordability</th>\n",
       "      <th>economy</th>\n",
       "      <th>education and health</th>\n",
       "      <th>quality of life</th>\n",
       "      <th>safety</th>\n",
       "      <th>Climate</th>\n",
       "      <th>title</th>\n",
       "      <th>totalyearlycompensation</th>\n",
       "      <th>yearsofexperience</th>\n",
       "      <th>tag</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>84000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>70000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>112000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Linux Kernel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>71000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>84000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52241</th>\n",
       "      <td>52241</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>105000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52242</th>\n",
       "      <td>52242</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>115000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52243</th>\n",
       "      <td>52243</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>115000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Full Stack</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52244</th>\n",
       "      <td>52244</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>188000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52245</th>\n",
       "      <td>52245</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>156000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Distributed Systems (Back-End)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52246 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      state  job_opportunity_rank  affordability  economy  \\\n",
       "0               0    Alabama                     2              0        3   \n",
       "1               1    Alabama                     2              0        3   \n",
       "2               2    Alabama                     2              0        3   \n",
       "3               3    Alabama                     2              0        3   \n",
       "4               4    Alabama                     2              0        3   \n",
       "...           ...        ...                   ...            ...      ...   \n",
       "52241       52241  Wisconsin                     1              3        1   \n",
       "52242       52242  Wisconsin                     1              3        1   \n",
       "52243       52243  Wisconsin                     1              3        1   \n",
       "52244       52244  Wisconsin                     1              3        1   \n",
       "52245       52245    Wyoming                     4              1        2   \n",
       "\n",
       "       education and health  quality of life  safety  Climate  \\\n",
       "0                         4                4       4        0   \n",
       "1                         4                4       4        0   \n",
       "2                         4                4       4        0   \n",
       "3                         4                4       4        0   \n",
       "4                         4                4       4        0   \n",
       "...                     ...              ...     ...      ...   \n",
       "52241                     0                0       0        4   \n",
       "52242                     0                0       0        4   \n",
       "52243                     0                0       0        4   \n",
       "52244                     0                0       0        4   \n",
       "52245                     2                3       0        4   \n",
       "\n",
       "                   title  totalyearlycompensation  yearsofexperience  \\\n",
       "0      Software Engineer                    84000                3.0   \n",
       "1      Software Engineer                    70000                2.0   \n",
       "2      Software Engineer                   112000                5.0   \n",
       "3      Software Engineer                    71000                2.0   \n",
       "4      Software Engineer                    84000                2.0   \n",
       "...                  ...                      ...                ...   \n",
       "52241  Software Engineer                   105000                0.0   \n",
       "52242  Software Engineer                   115000                2.0   \n",
       "52243  Software Engineer                   115000                0.0   \n",
       "52244  Software Engineer                   188000                8.0   \n",
       "52245  Software Engineer                   156000                7.0   \n",
       "\n",
       "                                  tag  Education  \n",
       "0                          Full Stack       -1.0  \n",
       "1                          Full Stack       -1.0  \n",
       "2                        Linux Kernel        1.0  \n",
       "3                          Full Stack       -1.0  \n",
       "4                          Full Stack       -1.0  \n",
       "...                               ...        ...  \n",
       "52241                      Full Stack       -1.0  \n",
       "52242                      Full Stack       -1.0  \n",
       "52243                      Full Stack       -1.0  \n",
       "52244                           Cloud       -1.0  \n",
       "52245  Distributed Systems (Back-End)        1.0  \n",
       "\n",
       "[52246 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data245_cleaneddata=pd.read_csv(\"https://raw.githubusercontent.com/Sowmyadiya/Data245-Project/master/Datasets/proj_data245_testing.csv\")\n",
    "# data245_cleaneddata=pd.read_csv(\"sowmyatesting.csv\")\n",
    "data245_cleaneddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.get_dummies(data = data245_cleaneddata, columns = ['title',\n",
    "                                                             'tag'])\n",
    "df = final_data.loc[ : , final_data.columns != 'state']\n",
    "\n",
    "target_data=data245_cleaneddata['state']\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52246, 2672)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "pca = PCA().fit(X)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=50, random_state=11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=50, random_state=11)  # reduce to two components\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52246, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pca.transform(X)\n",
    "data=pd.DataFrame(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19949    California\n",
       "22859    California\n",
       "17930    California\n",
       "10458    California\n",
       "41775    Washington\n",
       "            ...    \n",
       "11284    California\n",
       "44732    Washington\n",
       "38158         Texas\n",
       "860      California\n",
       "15795    California\n",
       "Name: state, Length: 36572, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(data,target_data,test_size=0.30,random_state=42)\n",
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "['California' 'Washington' 'California' ... 'Washington' 'Texas'\n",
      " 'California']\n",
      "Confusion Matrix:  [[   0    0    7 ...    0    0    0]\n",
      " [   0  112    0 ...    0    0    0]\n",
      " [   0    0   37 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ... 3706    0    0]\n",
      " [   0    0    0 ...    0    0    3]\n",
      " [   0    0    0 ...    0    0   46]]\n",
      "Accuracy :  83.10578027306367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmya/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                  precision    recall  f1-score   support\n",
      "\n",
      "       Alabama       0.00      0.00      0.00         7\n",
      "       Arizona       1.00      1.00      1.00       112\n",
      "      Arkansas       0.84      1.00      0.91        37\n",
      "    California       1.00      1.00      1.00      6853\n",
      "      Colorado       0.00      0.00      0.00       159\n",
      "   Connecticut       0.00      0.00      0.00        31\n",
      "      Delaware       0.00      0.00      0.00        20\n",
      "       Florida       0.00      0.00      0.00        72\n",
      "       Georgia       0.00      0.00      0.00       165\n",
      "         Idaho       0.00      0.00      0.00        16\n",
      "      Illinois       0.00      0.00      0.00       241\n",
      "       Indiana       0.00      0.00      0.00        32\n",
      "          Iowa       0.00      0.00      0.00         7\n",
      "        Kansas       0.00      0.00      0.00        11\n",
      "      Kentucky       0.00      0.00      0.00         6\n",
      "     Louisiana       0.00      0.00      0.00         8\n",
      "         Maine       0.00      0.00      0.00         1\n",
      "      Maryland       0.00      0.00      0.00        33\n",
      " Massachusetts       0.00      0.00      0.00       525\n",
      "      Michigan       0.00      0.00      0.00        73\n",
      "     Minnesota       0.00      0.00      0.00        80\n",
      "      Missouri       0.00      0.00      0.00        59\n",
      "       Montana       0.00      0.00      0.00         1\n",
      "      Nebraska       0.00      0.00      0.00         8\n",
      "        Nevada       0.00      0.00      0.00         4\n",
      " New Hampshire       0.00      0.00      0.00        10\n",
      "    New Jersey       0.00      0.00      0.00       143\n",
      "    New Mexico       0.00      0.00      0.00         2\n",
      "      New York       0.65      1.00      0.79      1483\n",
      "North Carolina       0.00      0.00      0.00       144\n",
      "  North Dakota       0.00      0.00      0.00         2\n",
      "          Ohio       0.00      0.00      0.00        70\n",
      "      Oklahoma       0.00      0.00      0.00         2\n",
      "        Oregon       0.00      0.00      0.00       176\n",
      "  Pennsylvania       0.00      0.00      0.00       156\n",
      "  Rhode Island       0.00      0.00      0.00         6\n",
      "South Carolina       0.00      0.00      0.00         8\n",
      "     Tennessee       0.00      0.00      0.00        26\n",
      "         Texas       0.30      1.00      0.46       789\n",
      "          Utah       0.00      0.00      0.00        65\n",
      "       Vermont       0.00      0.00      0.00         6\n",
      "      Virginia       0.00      0.00      0.00       269\n",
      "    Washington       1.00      1.00      1.00      3707\n",
      " West Virginia       0.00      0.00      0.00         3\n",
      "     Wisconsin       0.94      1.00      0.97        46\n",
      "\n",
      "      accuracy                           0.83     15674\n",
      "     macro avg       0.13      0.16      0.14     15674\n",
      "  weighted avg       0.76      0.83      0.78     15674\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "['California' 'Washington' 'California' ... 'Washington' 'Illinois'\n",
      " 'California']\n",
      "Confusion Matrix:  [[   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ... 3707    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "Accuracy :  85.77899706520353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmya/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report :                  precision    recall  f1-score   support\n",
      "\n",
      "       Alabama       0.00      0.00      0.00         7\n",
      "       Arizona       0.00      0.00      0.00       112\n",
      "      Arkansas       0.00      0.00      0.00        37\n",
      "    California       1.00      1.00      1.00      6853\n",
      "      Colorado       0.00      0.00      0.00       159\n",
      "   Connecticut       1.00      1.00      1.00        31\n",
      "      Delaware       0.00      0.00      0.00        20\n",
      "       Florida       0.00      0.00      0.00        72\n",
      "       Georgia       0.35      1.00      0.52       165\n",
      "         Idaho       0.00      0.00      0.00        16\n",
      "      Illinois       0.59      1.00      0.74       241\n",
      "       Indiana       0.00      0.00      0.00        32\n",
      "          Iowa       0.00      0.00      0.00         7\n",
      "        Kansas       0.00      0.00      0.00        11\n",
      "      Kentucky       0.00      0.00      0.00         6\n",
      "     Louisiana       0.00      0.00      0.00         8\n",
      "         Maine       0.00      0.00      0.00         1\n",
      "      Maryland       0.00      0.00      0.00        33\n",
      " Massachusetts       0.00      0.00      0.00       525\n",
      "      Michigan       0.00      0.00      0.00        73\n",
      "     Minnesota       0.00      0.00      0.00        80\n",
      "      Missouri       0.00      0.00      0.00        59\n",
      "       Montana       0.00      0.00      0.00         1\n",
      "      Nebraska       0.00      0.00      0.00         8\n",
      "        Nevada       0.00      0.00      0.00         4\n",
      " New Hampshire       0.00      0.00      0.00        10\n",
      "    New Jersey       0.00      0.00      0.00       143\n",
      "    New Mexico       0.00      0.00      0.00         2\n",
      "      New York       0.70      1.00      0.82      1483\n",
      "North Carolina       0.00      0.00      0.00       144\n",
      "  North Dakota       0.00      0.00      0.00         2\n",
      "          Ohio       0.00      0.00      0.00        70\n",
      "      Oklahoma       0.00      0.00      0.00         2\n",
      "        Oregon       0.64      1.00      0.78       176\n",
      "  Pennsylvania       0.00      0.00      0.00       156\n",
      "  Rhode Island       0.00      0.00      0.00         6\n",
      "South Carolina       0.00      0.00      0.00         8\n",
      "     Tennessee       0.00      0.00      0.00        26\n",
      "         Texas       0.44      1.00      0.61       789\n",
      "          Utah       0.00      0.00      0.00        65\n",
      "       Vermont       0.00      0.00      0.00         6\n",
      "      Virginia       0.00      0.00      0.00       269\n",
      "    Washington       1.00      1.00      1.00      3707\n",
      " West Virginia       0.00      0.00      0.00         3\n",
      "     Wisconsin       0.00      0.00      0.00        46\n",
      "\n",
      "      accuracy                           0.86     15674\n",
      "     macro avg       0.13      0.18      0.14     15674\n",
      "  weighted avg       0.78      0.86      0.81     15674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this program on your local python\n",
    "# interpreter, provided you have installed\n",
    "# the required libraries.\n",
    "\n",
    "# Importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function importing Dataset\n",
    "def importdata():\n",
    "\tbalance_data = pd.read_csv(\n",
    "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
    "'databases/balance-scale/balance-scale.data',\n",
    "\tsep= ',', header = None)\n",
    "\t\n",
    "\t# Printing the dataswet shape\n",
    "\tprint (\"Dataset Length: \", len(balance_data))\n",
    "\tprint (\"Dataset Shape: \", balance_data.shape)\n",
    "\t\n",
    "\t# Printing the dataset obseravtions\n",
    "\tprint (\"Dataset: \",balance_data.head())\n",
    "\treturn balance_data\n",
    "\n",
    "# Function to split the dataset\n",
    "def splitdataset(balance_data):\n",
    "\n",
    "\t# Separating the target variable\n",
    "\tX = balance_data.values[:, 1:5]\n",
    "\tY = balance_data.values[:, 0]\n",
    "\n",
    "\t# Splitting the dataset into train and test\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(\n",
    "\tX, Y, test_size = 0.3, random_state = 100)\n",
    "\t\n",
    "\treturn X, Y, X_train, X_test, y_train, y_test\n",
    "\t\n",
    "# Function to perform training with giniIndex.\n",
    "def train_using_gini(X_train, X_test, y_train):\n",
    "\n",
    "\t# Creating the classifier object\n",
    "\tclf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
    "\t\t\trandom_state = 100,max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "\t# Performing training\n",
    "\tclf_gini.fit(X_train, y_train)\n",
    "\treturn clf_gini\n",
    "\t\n",
    "# Function to perform training with entropy.\n",
    "def tarin_using_entropy(X_train, X_test, y_train):\n",
    "\n",
    "\t# Decision tree with entropy\n",
    "\tclf_entropy = DecisionTreeClassifier(\n",
    "\t\t\tcriterion = \"entropy\", random_state = 100,\n",
    "\t\t\tmax_depth = 3, min_samples_leaf = 5)\n",
    "\n",
    "\t# Performing training\n",
    "\tclf_entropy.fit(X_train, y_train)\n",
    "\treturn clf_entropy\n",
    "\n",
    "\n",
    "# Function to make predictions\n",
    "def prediction(X_test, clf_object):\n",
    "\n",
    "\t# Predicton on test with giniIndex\n",
    "\ty_pred = clf_object.predict(X_test)\n",
    "\tprint(\"Predicted values:\")\n",
    "\tprint(y_pred)\n",
    "\treturn y_pred\n",
    "\t\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "\t\n",
    "\tprint(\"Confusion Matrix: \",\n",
    "\t\tconfusion_matrix(y_test, y_pred))\n",
    "\t\n",
    "\tprint (\"Accuracy : \",\n",
    "\taccuracy_score(y_test,y_pred)*100)\n",
    "\t\n",
    "\tprint(\"Report : \",\n",
    "\tclassification_report(y_test, y_pred))\n",
    "\n",
    "# Driver code\n",
    "def main():\n",
    "\t\n",
    "\t# Building Phase\n",
    "\t#data = importdata()\n",
    "\tY = target_data\n",
    "\tX = df\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30,random_state=42)\n",
    "\tclf_gini = train_using_gini(X_train, X_test, y_train)\n",
    "\tclf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
    "# \tpickle_out=open(\"DecisionTree_data245.pkl\",\"wb\")\n",
    "# \tpickle.dump(clf_entropy,pickle_out)\n",
    "# \tpickle_out.close()\n",
    "\t\n",
    "\t# Operational Phase\n",
    "\tprint(\"Results Using Gini Index:\")\n",
    "\t\n",
    "\t# Prediction using gini\n",
    "\ty_pred_gini = prediction(X_test, clf_gini)\n",
    "\tcal_accuracy(y_test, y_pred_gini)\n",
    "\t\n",
    "\tprint(\"Results Using Entropy:\")\n",
    "\t# Prediction using entropy\n",
    "\ty_pred_entropy = prediction(X_test, clf_entropy)\n",
    "\tcal_accuracy(y_test, y_pred_entropy)\n",
    "\t\n",
    "\t\n",
    "# Calling main function\n",
    "if __name__==\"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9924078091106291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['California', 'Washington', 'California', ..., 'Washington',\n",
       "       'Colorado', 'California'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=16, max_leaf_nodes=60, random_state=70,criterion='gini')\n",
    "rnd_clf.fit(Xtrain, Ytrain)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(Xtest)\n",
    "print(accuracy_score(Ytest, y_pred_rf))\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out=open(\"RandomForest_data245.pkl\",\"wb\")\n",
    "pickle.dump(rnd_clf,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut',\n",
       "       'Delaware', 'Florida', 'Georgia', 'Idaho', 'Illinois', 'Indiana',\n",
       "       'Iowa', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Missouri', 'Nevada', 'New Hampshire', 'New Jersey', 'New York',\n",
       "       'North Carolina', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "       'Tennessee', 'Texas', 'Utah', 'Virginia', 'Washington',\n",
       "       'Wisconsin'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pandas import DataFrame\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmya/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:32] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9988516013780784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['California', 'Washington', 'California', ..., 'Washington',\n",
       "       'Colorado', 'California'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "XGB_clf = XGBClassifier()\n",
    "XGB_clf.fit(Xtrain, Ytrain)\n",
    "# make predictions for test data\n",
    "y_pred_XG = XGB_clf.predict(Xtest)\n",
    "print(accuracy_score(Ytest, y_pred_XG))\n",
    "y_pred_XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alabama', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
       "       'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Idaho',\n",
       "       'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "       'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "       'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'Ohio',\n",
       "       'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island',\n",
       "       'South Carolina', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n",
       "       'Virginia', 'Washington', 'West Virginia', 'Wisconsin'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_XG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out=open(\"s_XGBoost_data245.pkl\",\"wb\")\n",
    "pickle.dump(XGB_clf,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sowmya/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/sowmya/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:10:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  1, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:11:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  2, Training/Test Split Distribution: , Accuracy: 1.000\n",
      "[16:12:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  3, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:13:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  4, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:14:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  5, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:15:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  6, Training/Test Split Distribution: , Accuracy: 0.998\n",
      "[16:16:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  7, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:17:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  8, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "[16:18:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold:  9, Training/Test Split Distribution: , Accuracy: 1.000\n",
      "[16:19:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Fold: 10, Training/Test Split Distribution: , Accuracy: 0.999\n",
      "\n",
      "\n",
      "Cross-Validation accuracy: 0.999 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#\n",
    "# Create an instance of Pipeline\n",
    "#\n",
    "pipeline = make_pipeline(XGBClassifier())\n",
    "#Xtrain,Xtest,Ytrain,Ytest\n",
    "# Create an instance of StratifiedKFold which can be used to get indices of different training and test folds\n",
    "#\n",
    "strtfdKFold = StratifiedKFold(n_splits=10)\n",
    "kfold = strtfdKFold.split(Xtrain, Ytrain)\n",
    "scores = []\n",
    "#\n",
    "#\n",
    "#\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipeline.fit(Xtrain.iloc[train, :], Ytrain.iloc[train])\n",
    "    score = pipeline.score(Xtrain.iloc[test, :], Ytrain.iloc[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Training/Test Split Distribution: , Accuracy: %.3f' % (k+1, score))\n",
    " \n",
    "print('\\n\\nCross-Validation accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/slundberg/shap.git\n",
      "  Cloning https://github.com/slundberg/shap.git to /private/var/folders/gf/7qz7pmws6zl3cxyfck9n1j7m0000gn/T/pip-req-build-yhirmgzg\n",
      "  Running command git clone --filter=blob:none -q https://github.com/slundberg/shap.git /private/var/folders/gf/7qz7pmws6zl3cxyfck9n1j7m0000gn/T/pip-req-build-yhirmgzg\n",
      "  Resolved https://github.com/slundberg/shap.git to commit 429fb3e0ac2ef179f1cff7e1a64b4f7b26f41eb5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing wheel metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting packaging>20.9\n",
      "  Downloading packaging-21.2-py3-none-any.whl (40 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40 kB 2.7 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (1.19.2)\n",
      "Requirement already satisfied: numba in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (0.51.2)\n",
      "Requirement already satisfied: scipy in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (1.5.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (4.50.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (0.23.2)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cloudpickle in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (1.6.0)\n",
      "Requirement already satisfied: pandas in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from shap==0.40.0) (1.1.3)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from packaging>20.9->shap==0.40.0) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from numba->shap==0.40.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from numba->shap==0.40.0) (0.34.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from pandas->shap==0.40.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from pandas->shap==0.40.0) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->shap==0.40.0) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->shap==0.40.0) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sowmya/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->shap==0.40.0) (1.15.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.40.0-cp38-cp38-macosx_10_9_x86_64.whl size=433628 sha256=89eb0ca9763ee0d8c57390e338a48bc49e6d0ef863e09e9db0ea5dbb9d13126a\n",
      "  Stored in directory: /private/var/folders/gf/7qz7pmws6zl3cxyfck9n1j7m0000gn/T/pip-ephem-wheel-cache-6e_p4qpb/wheels/43/d4/b7/852c8c4711da053ae2ad230f1a8b270ca2ad3fc26ab00b1a03\n",
      "Successfully built shap\n",
      "Installing collected packages: slicer, packaging, shap\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.4\n",
      "    Uninstalling packaging-20.4:\n",
      "      Successfully uninstalled packaging-20.4\n",
      "Successfully installed packaging-21.2 shap-0.40.0 slicer-0.0.7\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/Users/sowmya/opt/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/slundberg/shap.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# clf.fit(X_train_pca, Ytrain)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred_rf = clf.predict(X_test_pca)\n",
    "# print(accuracy_score(Ytest, y_pred_rf))\n",
    "# y_pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# ada_clf = AdaBoostClassifier(n_estimators=4,\n",
    "#      learning_rate=0.5)\n",
    "# ada_clf.fit(Xtrain, Ytrain)\n",
    "# y_pred = ada_clf.predict(Xtest)\n",
    "# print(accuracy_score(Ytest, y_pred))\n",
    "# np.unique(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
